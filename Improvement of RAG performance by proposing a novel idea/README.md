# 1. 배경 & 목적

---

- 주제명  : Improvement of retrieval-augmented generation performance by proposing a novel idea
- 목적
    - 주어진 documents에 noisy가 있다고 가정한 상태에서 knowledge-intensive한 질문에 대해 최고의 답변을 생성해내는 RAG 구현
    - noisy document에는 문자 또는 단어 삭제, 위치 교체, 임의의 요소 대체 등이 포함되며, 일부 문서에는 사실과 다른 정보가 포함됨

# 2. 주최 & 참가 대상 & 성과

---

- 주최 : 2024-1 기초자연어처리 Final Project
- 참가 자격 및 팀 인원 제한 사항: 3명 팀
- 성과 : Top 17%

# 3. 대회 기간

---

- 대회 마감 : 2024년 6월 16일

# 4. 담당 역할

---

- 텍스트 데이터 전처리, Vector DB 구현, Retrival 구현, 실험 버전 관리

# 5. 분석 과정

---

### 5.1 Preprocessing Wiki Data

- ‘remove_special_characters’ function : 주어진 문장에서 영어 알파벳, 숫자, 공백을 제외한 모든 특수 문자를 제거하는 전처리 작업을 수행하는 기능을 한다.

### 5.2 Construct RAG Architecture

- ‘VectorDatabase’ class : 위키 문서 데이터를 기반으로 벡터 데이터베이스를 생성하고 유사 문서 검색 기능을 한다. init 메서드에서는 문서 데이터를 입력받은 후 TF-IDF를 통해서 벡터화하고 document_embeddings 변수에 저장한다. TF_IDF란 Term Frequency-Inverse Document Frequency의 약자로, 문서의 집합에서 단어의 중요도를 측정하여 수치화된 벡터로 변환한다.
- search_similar_doc 메서드에서는 쿼리를 입력받은 후 TF-IDF 벡터화하여 query_embedding 변수에 저장한다. 그 후 데이터베이스에 저장된 문서 벡터와 쿼리 벡터 간의 코사인 유사도를 계산하고, 가장 유사한 문서의 인덱스를 도출한다. 도출된 인덱스를 사용해서 가장 유사한 문서를 최종 출력한다.
- ‘generate_with_prompt_tuning’ function : 쿼리를 바탕으로 생성형 AI모델을 활용해서 답변을 생성하는 기능을 한다. 쿼리 앞에 질문 유형과 답변 형식을 명시하는 프롬포트를 생성했다. 쿼리를 토큰화 한 후, max_length와 padding 등의 파라미터를 설정하여 입력 데이터를 생성한다. 그 후 생성된 입력 데이터를 gemma 모델에 넣어 답변을 생성했다. 생성된 답변은 디코딩하여 문자열 형태로 반환했다. 최종적으로 답변 앞뒤 공백과 불필요한 문자열을 제거하여 최종 답변을 반환했다.
- ‘rag’ function : 문서 데이터와 쿼리 목록을 입력 받아 쿼리 별 답변을 생성하고 관련 문서를 반환하는 기능을 한다.. 먼저 입력된 문서 데이터를 기반으로 vector_db 객체를 생성한다. 각 쿼리를 사용해서 vecotr_db에서 유사 문서를 검색한다. 다음으로 generative_with_prompt_tuning 함수를 사용해서 질문에 대한 짧은 답변을 생성한다. 예측 결과 딕셔너리에 쿼리 인덱스를 키값으로 하여 생성된 답변과 관련 문서를 저장함으로써 최종적으로 쿼리 별 예측 결과 딕셔너리를 반환했다.

### 5.3 Running Rag

- rag 함수를 호수를 호출하여 질의 응답 시스템을 실행한다. document data로는txt 데이터의 문장 100,000개를 사용해주었고 쿼리 목록으로는 qa_test.json 데이터의 question 9,785개를 사용했다.

### 5.4 Post Processing

- spacy, symspellpy : 이 모듈은 위키 데이터의 오탈자를 수정하기 위해 사용하였다. spacy 모델은 en_core_web_md를 사용해 각 문장을 NER 토큰으로 구분하는데 사용하였다. 이렇게 사용한 이유는 오탈자 수정 시 고유 명사를 수정하는 경우를 배제하기 위해서이다.
- 오타 수정은 symspelly의txt를 사용하였다. 이 파일에는 자주 사용하는 영어 단어와 그 빈도수를 저장한 사전형 파일이다. 입력된 각 문장을 NER 단위로 분리한 다음 고유명사를 제외한 나머지 단어를 하나씩 사전 내 단어와 비교하면서 오탈자가 있는지 확인하는 과정을 거친다. 이때, 최대 수정 개수는 알파벳 3개까지로 설정하였다. 일부 단어의 경우 고유명사로 취급되어 수정 가능한 단어임에도 수정되지 않는 경우가 있었다. 이 경우 해당 고유명사를 오타 수정한 다음 수정된 단어가 사전에 있는지 확인하였다. 사전에 있으면 수정된 단어를 사용하였고 사전에 없으면 해당 고유명사를 사전에 추가한 다음 사용하였다.

### 5.5 Experiment Performance

- 실험 성능은 아래와 같이 표를 만들어서 관리했다. 앞서 기술한 구현 방식은 version 7에 해당하는 방식으로 리더보드 상 가장 좋은 성능을 보였다. 이를 기반으로  submission 파일을 생성해서 촤종 제출하였다.

![RAG](https://github.com/user-attachments/assets/74ff052b-862e-4302-b837-9de9881e9f80)

# 6. 느낀점

---

- RAG의 구성 요소들을 직접 구현해보며 외부 데이터베이스에서 관련 정보를 검색하고, 정확하고 풍부한 답변을 생성해내는 과정을 직접 경험할 수 있었습니다.
- 유사도 기반으로 Query와 관련된 문서를 찾아오는 과정이 신기하였고, 찾은 문서를 활용해서 적절한 Prompt를 작성하는 것이 퀄리티 좋은 답변 생성에 있어서 중요하다고 느꼈습니다.
- 좋은 답변을 생성해내기 위해서 Prompt Tuning을 진행하며 실험을 진행하였고 해당 과정에서 Prompt에 예시를 포함하거나 역할을 부여하면 더욱 좋은 답변을 한다는 것을 알게 되었습니다.
- VecotrDB 클래스를 구현하면서 대용량의 데이터를 가져오는데 어려움을 겪었습니다. 추후에는 데이터를 효율적으로 저장하고 불러오는 과정을 고민해서 RAG를 구현해보면 좋을 것 같다고 생각했습니다.


# 7. 증빙 자료

---

- 대회 링크

https://www.kaggle.com/t/527b1bbc05f8494996380608afdce97d
