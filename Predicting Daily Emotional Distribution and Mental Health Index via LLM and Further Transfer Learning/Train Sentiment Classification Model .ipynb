{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 17:17:49.418168: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 17:17:50.558766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, top_k_accuracy_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from datasets import Features, Value, ClassLabel, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import optuna\n",
    "from optuna.samplers import CmaEsSampler,TPESampler\n",
    "\n",
    "TEST_RATIO = 0.1 \n",
    "MASTER_SEED = 42\n",
    "MODELS = (\n",
    "    'klue/roberta-base', # 0\n",
    "    'klue/roberta-large', # 1\n",
    "    'klue/bert-base', # 2\n",
    "    'monologg/koelectra-base-v3-discriminator' # 3\n",
    "    \n",
    ")\n",
    "MODEL_ID = 1\n",
    "MODEL_NAME = MODELS[MODEL_ID]\n",
    "SENTIMENT_CLASS = ['ÌñâÎ≥µ','Î∂ÑÎÖ∏','Ïä¨Ìîî','Ï§ëÎ¶Ω']\n",
    "NUM_LABELS = len(SENTIMENT_CLASS)\n",
    "\n",
    "model = trainer = None\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Data, Tokenizer, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sentiment/sentiment_label_df_v2.csv')\n",
    "df = df[df['labels'].isin(SENTIMENT_CLASS)]\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Î∂ÑÎÖ∏    10417\n",
       "Ïä¨Ìîî    10128\n",
       "Ï§ëÎ¶Ω     7421\n",
       "ÌñâÎ≥µ     7339\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare data in BERT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0385c39b3a764cdca6057935814e135c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51910cab6bdd48cdb149f19f99eecc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define features\n",
    "emotion_features = Features({'Sentence' : Value(dtype='string'), 'labels' : ClassLabel(names=SENTIMENT_CLASS)})\n",
    "# Split train and test set\n",
    "train_df, eval_df = train_test_split(df, test_size = TEST_RATIO, random_state=MASTER_SEED)\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize(text):\n",
    "    return tokenizer(text[\"Sentence\"])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df, features=emotion_features, preserve_index=False).map(tokenize, batched=True)\n",
    "eval_dataset = Dataset.from_pandas(eval_df, features=emotion_features, preserve_index=False).map(tokenize, batched=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a function to compute metrics and declare a trainer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred_n_label):\n",
    "    out, label = pred_n_label\n",
    "    pred = np.argmax(out, axis=-1)\n",
    "\n",
    "    # Total Accuracy\n",
    "    acc = accuracy_score(label, pred)\n",
    "    # Top 2 Accuracy\n",
    "    top_k_acc = top_k_accuracy_score(label, out)\n",
    "    # F1 score (macro)\n",
    "    f1 = f1_score(label, pred, average=\"macro\")\n",
    "    # Per-class Accuracy\n",
    "    cm = confusion_matrix(label, pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    cls_acc = []\n",
    "    for cl, acc_per_cls in zip(SENTIMENT_CLASS, cm.diagonal()):\n",
    "        cls_acc.append(acc_per_cls)\n",
    "\n",
    "    return {\n",
    "        'accuracy':acc, 'f1':f1,\n",
    "        'top_k_accuracy':top_k_acc,\n",
    "        **dict(zip(SENTIMENT_CLASS, cls_acc))\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning with Pre-training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='../Sentiment_Analysis/output/' + MODEL_NAME.split('/')[1] + '_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    do_train=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=128,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.1,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6,\n",
    "    num_train_epochs=5,\n",
    "    warmup_ratio=0.06,\n",
    "    save_strategy='epoch',\n",
    "    seed=MASTER_SEED,\n",
    "    data_seed=MASTER_SEED,\n",
    "    remove_unused_columns=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT-base\n",
    "    - bert-base_20240619_115423 / checkpoint-9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9930/9930 1:12:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313700</td>\n",
       "      <td>0.283246</td>\n",
       "      <td>0.885868</td>\n",
       "      <td>0.898096</td>\n",
       "      <td>0.985273</td>\n",
       "      <td>0.931526</td>\n",
       "      <td>0.831120</td>\n",
       "      <td>0.832502</td>\n",
       "      <td>0.988357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.269070</td>\n",
       "      <td>0.898046</td>\n",
       "      <td>0.907358</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.952924</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>0.838485</td>\n",
       "      <td>0.996119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.302093</td>\n",
       "      <td>0.897479</td>\n",
       "      <td>0.907378</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.941512</td>\n",
       "      <td>0.843454</td>\n",
       "      <td>0.854437</td>\n",
       "      <td>0.987063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.335035</td>\n",
       "      <td>0.903144</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>0.988105</td>\n",
       "      <td>0.948645</td>\n",
       "      <td>0.853890</td>\n",
       "      <td>0.851446</td>\n",
       "      <td>0.996119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.902860</td>\n",
       "      <td>0.912190</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.842505</td>\n",
       "      <td>0.860419</td>\n",
       "      <td>0.996119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3894410729408264,\n",
       " 'eval_accuracy': 0.9028603794958935,\n",
       " 'eval_f1': 0.9121904075828369,\n",
       " 'eval_top_k_accuracy': 0.9869725290286038,\n",
       " 'eval_ÌñâÎ≥µ': 0.9514978601997147,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8425047438330171,\n",
       " 'eval_Ïä¨Ìîî': 0.8604187437686939,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9961190168175937,\n",
       " 'eval_runtime': 4.1276,\n",
       " 'eval_samples_per_second': 855.458,\n",
       " 'eval_steps_per_second': 1.696,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19860' max='19860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19860/19860 1:20:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.320022</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.899955</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.927247</td>\n",
       "      <td>0.829222</td>\n",
       "      <td>0.841476</td>\n",
       "      <td>0.992238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.302943</td>\n",
       "      <td>0.900312</td>\n",
       "      <td>0.909663</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.851992</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.402959</td>\n",
       "      <td>0.901728</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.988389</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.837761</td>\n",
       "      <td>0.869392</td>\n",
       "      <td>0.992238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.457510</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.913506</td>\n",
       "      <td>0.986406</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>0.849146</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>0.997413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.512838</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.913720</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>0.947218</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.856431</td>\n",
       "      <td>0.997413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.512837827205658,\n",
       " 'eval_accuracy': 0.9048428207306712,\n",
       " 'eval_f1': 0.9137204108794539,\n",
       " 'eval_top_k_accuracy': 0.9866893231379212,\n",
       " 'eval_ÌñâÎ≥µ': 0.9472182596291013,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8548387096774194,\n",
       " 'eval_Ïä¨Ìîî': 0.8564307078763709,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9974126778783958,\n",
       " 'eval_runtime': 6.0728,\n",
       " 'eval_samples_per_second': 581.442,\n",
       " 'eval_steps_per_second': 2.305,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Koelectra\n",
    "    - koelectra-base-v3-discriminator_20240618_141343/checkpoint-19860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19860' max='19860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19860/19860 1:22:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.340684</td>\n",
       "      <td>0.881337</td>\n",
       "      <td>0.893789</td>\n",
       "      <td>0.983008</td>\n",
       "      <td>0.921541</td>\n",
       "      <td>0.807400</td>\n",
       "      <td>0.852443</td>\n",
       "      <td>0.983182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.301789</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.910317</td>\n",
       "      <td>0.988389</td>\n",
       "      <td>0.954351</td>\n",
       "      <td>0.836812</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.380444</td>\n",
       "      <td>0.901728</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.945792</td>\n",
       "      <td>0.875712</td>\n",
       "      <td>0.828514</td>\n",
       "      <td>0.992238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.428549</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.987822</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.829222</td>\n",
       "      <td>0.878365</td>\n",
       "      <td>0.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.471694</td>\n",
       "      <td>0.902577</td>\n",
       "      <td>0.912333</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.839658</td>\n",
       "      <td>0.863410</td>\n",
       "      <td>0.994825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4716937839984894,\n",
       " 'eval_accuracy': 0.902577173605211,\n",
       " 'eval_f1': 0.9123329793448183,\n",
       " 'eval_top_k_accuracy': 0.9875389408099688,\n",
       " 'eval_ÌñâÎ≥µ': 0.9514978601997147,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8396584440227703,\n",
       " 'eval_Ïä¨Ìîî': 0.8634097706879362,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9948253557567918,\n",
       " 'eval_runtime': 6.3286,\n",
       " 'eval_samples_per_second': 557.947,\n",
       " 'eval_steps_per_second': 2.212,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RoBERTa-base\n",
    "    - roberta-base_20240619_103559 / checkpoint-9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9930/9930 1:13:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>0.294761</td>\n",
       "      <td>0.890116</td>\n",
       "      <td>0.900991</td>\n",
       "      <td>0.985273</td>\n",
       "      <td>0.928673</td>\n",
       "      <td>0.857685</td>\n",
       "      <td>0.831505</td>\n",
       "      <td>0.975420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.285452</td>\n",
       "      <td>0.895214</td>\n",
       "      <td>0.905874</td>\n",
       "      <td>0.990088</td>\n",
       "      <td>0.955777</td>\n",
       "      <td>0.781784</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.306372</td>\n",
       "      <td>0.902577</td>\n",
       "      <td>0.911655</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.928673</td>\n",
       "      <td>0.885199</td>\n",
       "      <td>0.832502</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.386180</td>\n",
       "      <td>0.901444</td>\n",
       "      <td>0.910688</td>\n",
       "      <td>0.988389</td>\n",
       "      <td>0.947218</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.429234</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.909847</td>\n",
       "      <td>0.988105</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.834915</td>\n",
       "      <td>0.870389</td>\n",
       "      <td>0.989651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4292335510253906,\n",
       " 'eval_accuracy': 0.9005947323704333,\n",
       " 'eval_f1': 0.9098473969503202,\n",
       " 'eval_top_k_accuracy': 0.9881053525913339,\n",
       " 'eval_ÌñâÎ≥µ': 0.9443651925820257,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8349146110056926,\n",
       " 'eval_Ïä¨Ìîî': 0.8703888334995015,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9896507115135834,\n",
       " 'eval_runtime': 4.0881,\n",
       " 'eval_samples_per_second': 863.73,\n",
       " 'eval_steps_per_second': 1.712,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RoBERTa-large\n",
    "    - roberta-large_20240417_122910 / checkpoint-9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9930/9930 1:37:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.301868</td>\n",
       "      <td>0.888983</td>\n",
       "      <td>0.898662</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>0.961484</td>\n",
       "      <td>0.910816</td>\n",
       "      <td>0.732802</td>\n",
       "      <td>0.996119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.272995</td>\n",
       "      <td>0.909657</td>\n",
       "      <td>0.918584</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.853890</td>\n",
       "      <td>0.874377</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.365211</td>\n",
       "      <td>0.908241</td>\n",
       "      <td>0.917381</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.952924</td>\n",
       "      <td>0.835863</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>0.994825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.429691</td>\n",
       "      <td>0.909941</td>\n",
       "      <td>0.918793</td>\n",
       "      <td>0.989805</td>\n",
       "      <td>0.952924</td>\n",
       "      <td>0.851044</td>\n",
       "      <td>0.877368</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.515261</td>\n",
       "      <td>0.909941</td>\n",
       "      <td>0.918737</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.952924</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.869392</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5152614116668701,\n",
       " 'eval_accuracy': 0.9099405267629567,\n",
       " 'eval_f1': 0.9187373072319894,\n",
       " 'eval_top_k_accuracy': 0.9875389408099688,\n",
       " 'eval_ÌñâÎ≥µ': 0.9529243937232525,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8586337760910816,\n",
       " 'eval_Ïä¨Ìîî': 0.8693918245264207,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9935316946959897,\n",
       " 'eval_runtime': 10.3687,\n",
       " 'eval_samples_per_second': 340.545,\n",
       " 'eval_steps_per_second': 0.675,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1e-5, step=1e-8)\n",
    "    }\n",
    "    args = TrainingArguments(\n",
    "        output_dir='../Sentiment_Analysis/tuning_output/' + MODEL_NAME.split('/')[1] + '_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        do_train=True,\n",
    "        evaluation_strategy='epoch',\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=128,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=params['learning_rate'],\n",
    "        weight_decay=0.1,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.98,\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_ratio=0.06,\n",
    "        save_strategy='epoch',\n",
    "        seed=MASTER_SEED,\n",
    "        data_seed=MASTER_SEED,\n",
    "        remove_unused_columns=True,\n",
    "    )\n",
    "    trainer = Trainer(model=model, tokenizer=tokenizer, args=args, data_collator=data_collator, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    result = trainer.evaluate()\n",
    "    return result['eval_accuracy'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameter Tuning - TPES Sampler(Î≤îÏ£ºÌòï, Ïã§ÏàòÌòï Î≥ÄÏàò Ï†ÅÏ†à)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Optuna Optimization\n",
    "num_trials = 10\n",
    "sampler = TPESampler(seed=MASTER_SEED)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler) \n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters : \", best_params)\n",
    "\n",
    "# Save Best Parameters for text file\n",
    "file_path = '../Sentiment_Analysis/tuning_output/' + MODEL_NAME.split('/')[1] + '_' + 'tpes_optuna_best_params_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + 'txt',\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"Best Parameters:\\n\")\n",
    "    for key, value in best_params.items():\n",
    "        file.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best ParamsÏúºÎ°ú Train\n",
    "    - finetune_roberta-large_20240417_173155/ checkpoint-9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9930/9930 37:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.482681</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>0.912995</td>\n",
       "      <td>0.964599</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.844402</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480979</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>0.913370</td>\n",
       "      <td>0.964033</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.845351</td>\n",
       "      <td>0.865404</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480698</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>0.913126</td>\n",
       "      <td>0.964033</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.845351</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480520</td>\n",
       "      <td>0.903993</td>\n",
       "      <td>0.913298</td>\n",
       "      <td>0.964316</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.848197</td>\n",
       "      <td>0.862413</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.482241</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.963750</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.845351</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.990944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gayeon42/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4822412729263306,\n",
       " 'eval_accuracy': 0.9037099971679411,\n",
       " 'eval_f1': 0.9130585861213216,\n",
       " 'eval_top_k_accuracy': 0.9637496459926367,\n",
       " 'eval_ÌñâÎ≥µ': 0.9514978601997147,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.8453510436432637,\n",
       " 'eval_Ïä¨Ìîî': 0.864406779661017,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9909443725743855,\n",
       " 'eval_runtime': 3.715,\n",
       " 'eval_samples_per_second': 950.481,\n",
       " 'eval_steps_per_second': 1.884,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../Sentiment_Analysis/tuning_output/finetune_' + MODEL_NAME.split('/')[1] + '_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    do_train=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    weight_decay=0.1,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.98,\n",
    "    adam_epsilon = 1e-6,\n",
    "    warmup_ratio=0.06,\n",
    "    save_strategy='epoch',\n",
    "    seed=MASTER_SEED,\n",
    "    data_seed=MASTER_SEED,\n",
    "    remove_unused_columns=True,\n",
    ")\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, data_collator=data_collator, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning with Further Pre-training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Î∂ÑÎÖ∏    12487\n",
       "Ïä¨Ìîî    12220\n",
       "ÌñâÎ≥µ     7895\n",
       "Ï§ëÎ¶Ω     7703\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Youtube Label Data\n",
    "youtube_label_df = pd.read_csv('../data/youtube_process/label_youtube_df.csv')[['clean_text','clean_sentiment']][:5000]\n",
    "youtube_label_df.rename(columns={'clean_text':'Sentence', 'clean_sentiment':'labels'},inplace=True)\n",
    "aihub_youtube_df = pd.concat([df,youtube_label_df])\n",
    "aihub_youtube_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best pretraining model(roberta-large-tpes_tuning)\n",
    "pretrain_model_path = '../Sentiment_Analysis/tuning_output/finetune_roberta-large_20240417_173155/checkpoint-9930'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrain_model_path,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model_path)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f249e6e435041ea8cd231874035bd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce1078bedf347c6a8e7d50fa9246ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define features\n",
    "emotion_features = Features({'Sentence' : Value(dtype='string'), 'labels' : ClassLabel(names=SENTIMENT_CLASS)})\n",
    "# Split train and test set\n",
    "train_df, eval_df = train_test_split(aihub_youtube_df, test_size = TEST_RATIO, random_state=MASTER_SEED)\n",
    "# Tokenize dataset\n",
    "def tokenize(text):\n",
    "    return tokenizer(text[\"Sentence\"])\n",
    "train_dataset = Dataset.from_pandas(train_df, features=emotion_features, preserve_index=False).map(tokenize, batched=True)\n",
    "eval_dataset = Dataset.from_pandas(eval_df, features=emotion_features, preserve_index=False).map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon42/.local/lib/python3.9/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='../Sentiment_Analysis/output/further_pretrain_robert-large_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    do_train=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=128,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.1,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6,\n",
    "    num_train_epochs=5,\n",
    "    warmup_ratio=0.06,\n",
    "    save_strategy='epoch',\n",
    "    seed=MASTER_SEED,\n",
    "    data_seed=MASTER_SEED,\n",
    "    remove_unused_columns=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45345' max='45345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45345/45345 3:35:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top K Accuracy</th>\n",
       "      <th>ÌñâÎ≥µ</th>\n",
       "      <th>Î∂ÑÎÖ∏</th>\n",
       "      <th>Ïä¨Ìîî</th>\n",
       "      <th>Ï§ëÎ¶Ω</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.515233</td>\n",
       "      <td>0.876209</td>\n",
       "      <td>0.892840</td>\n",
       "      <td>0.975936</td>\n",
       "      <td>0.908854</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.756275</td>\n",
       "      <td>0.967914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.499468</td>\n",
       "      <td>0.903746</td>\n",
       "      <td>0.916485</td>\n",
       "      <td>0.978913</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.836437</td>\n",
       "      <td>0.967914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.552820</td>\n",
       "      <td>0.905234</td>\n",
       "      <td>0.916734</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.919271</td>\n",
       "      <td>0.897656</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.975936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.682484</td>\n",
       "      <td>0.909452</td>\n",
       "      <td>0.919912</td>\n",
       "      <td>0.976681</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.869636</td>\n",
       "      <td>0.975936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.782420</td>\n",
       "      <td>0.913173</td>\n",
       "      <td>0.922544</td>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.928385</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>0.979947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.78242027759552,\n",
       " 'eval_accuracy': 0.9131729099479038,\n",
       " 'eval_f1': 0.9225442614054467,\n",
       " 'eval_top_k_accuracy': 0.9749441825849665,\n",
       " 'eval_ÌñâÎ≥µ': 0.9283854166666666,\n",
       " 'eval_Î∂ÑÎÖ∏': 0.89453125,\n",
       " 'eval_Ïä¨Ìîî': 0.8825910931174089,\n",
       " 'eval_Ï§ëÎ¶Ω': 0.9799465240641712,\n",
       " 'eval_runtime': 45.8745,\n",
       " 'eval_samples_per_second': 87.87,\n",
       " 'eval_steps_per_second': 0.698,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  tokenizer=tokenizer, \n",
    "                  args=args, \n",
    "                  data_collator=data_collator, \n",
    "                  train_dataset=train_dataset, \n",
    "                  eval_dataset=eval_dataset, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37f6aa06d024e79ccb1de33f6d75806f7fe1df6b69589799cfe84f4b04ae4ba6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
